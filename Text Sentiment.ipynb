{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c43e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bd4047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16dcea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/nissasyfsgt/DATASET/main/dataset_train.csv', encoding='latin-1')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/nissasyfsgt/DATASET/main/dataset_test.csv', encoding='latin-1')\n",
    "alay_dict = pd.read_csv('https://raw.githubusercontent.com/nissasyfsgt/DATASET/main/new_kamusalay.csv', encoding='latin-1', header=None)\n",
    "alay_dict = alay_dict.rename(columns={0: 'original', \n",
    "                                      1: 'replacement'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091e82e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (10535, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\xf0\\x9f\\x93\\x8c Himmler merupakan pimpinan de...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USER Iya anjir dah'</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USER Adatuh temen sekelas di sma, dia cakep im...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER USER USER USER Mongomong soal ospek, jadi...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bajingan punya line'</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kenali aku lebih dalam. Maka kamu akan mengert...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dalam acara Back to Campus di Fakultas Ilmu Bu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>itu kalo USER beneran otoriter sebagaimana dil...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>USER Seperti melihat punuk onta'</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>USER USER Aseng yg bajingan spt ahok beserta k...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>USER biar makin panas alias babi kaaaaau\\n wwk...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>USER Kenapa? Terguncang ente mendengarnya pak?...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Main ke pos ronda ngarepin temen ngobrol, yg a...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mengapa bukan PT Antam yang yang dipinjami ole...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweet Sentiment\n",
       "0   \\xf0\\x9f\\x93\\x8c Himmler merupakan pimpinan de...  Positive\n",
       "1                                 USER Iya anjir dah'  Negative\n",
       "2   USER Adatuh temen sekelas di sma, dia cakep im...  Positive\n",
       "3   USER USER USER USER Mongomong soal ospek, jadi...  Positive\n",
       "4                                Bajingan punya line'  Negative\n",
       "5   Kenali aku lebih dalam. Maka kamu akan mengert...  Negative\n",
       "6   Dalam acara Back to Campus di Fakultas Ilmu Bu...  Positive\n",
       "7   USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...  Positive\n",
       "8   itu kalo USER beneran otoriter sebagaimana dil...  Positive\n",
       "9                    USER Seperti melihat punuk onta'  Positive\n",
       "10  USER USER Aseng yg bajingan spt ahok beserta k...  Negative\n",
       "11  USER biar makin panas alias babi kaaaaau\\n wwk...  Negative\n",
       "12  USER Kenapa? Terguncang ente mendengarnya pak?...  Positive\n",
       "13  Main ke pos ronda ngarepin temen ngobrol, yg a...  Negative\n",
       "14  Mengapa bukan PT Antam yang yang dipinjami ole...  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape: \", train.shape)\n",
    "train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "215163b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (15167, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>replacement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anakjakartaasikasik</td>\n",
       "      <td>anak jakarta asyik asyik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pakcikdahtua</td>\n",
       "      <td>pak cik sudah tua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pakcikmudalagi</td>\n",
       "      <td>pak cik muda lagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3tapjokowi</td>\n",
       "      <td>tetap jokowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3x</td>\n",
       "      <td>tiga kali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aamiin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aamiinn</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aamin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aammiin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abis</td>\n",
       "      <td>habis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abisin</td>\n",
       "      <td>habiskan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acau</td>\n",
       "      <td>kacau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>achok</td>\n",
       "      <td>ahok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ad</td>\n",
       "      <td>ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adek</td>\n",
       "      <td>adik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               original               replacement\n",
       "0   anakjakartaasikasik  anak jakarta asyik asyik\n",
       "1          pakcikdahtua         pak cik sudah tua\n",
       "2        pakcikmudalagi         pak cik muda lagi\n",
       "3           t3tapjokowi              tetap jokowi\n",
       "4                    3x                 tiga kali\n",
       "5                aamiin                      amin\n",
       "6               aamiinn                      amin\n",
       "7                 aamin                      amin\n",
       "8               aammiin                      amin\n",
       "9                  abis                     habis\n",
       "10               abisin                  habiskan\n",
       "11                 acau                     kacau\n",
       "12                achok                      ahok\n",
       "13                   ad                       ada\n",
       "14                 adek                      adik"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape: \", alay_dict.shape)\n",
    "alay_dict.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0070e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_unnecessary_char(text):\n",
    "    text = re.sub('\\n',' ',text) # Remove every '\\n'\n",
    "    text = re.sub('rt',' ',text) # Remove every retweet symbol\n",
    "    text = re.sub('user',' ',text) # Remove every username\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text) # Remove every URL\n",
    "    text = re.sub('  +', ' ', text) # Remove extra spaces\n",
    "    return text\n",
    "    \n",
    "def remove_nonaplhanumeric(text):\n",
    "    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n",
    "    return text\n",
    "\n",
    "alay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\n",
    "def normalize_alay(text):\n",
    "    return ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    "\n",
    "def preprocess(text):\n",
    "    text = lowercase(text) # 1\n",
    "    text = remove_nonaplhanumeric(text) # 2\n",
    "    text = remove_unnecessary_char(text) # 2\n",
    "    text = normalize_alay(text) # 3\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bbc9cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Tweet'] = train['Tweet'].apply(preprocess)\n",
    "test['Tweet'] = test['Tweet'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4554a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2634, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xf0 x9f x93 x8c himmler merupakan pimpinan di...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iya anjir sudah</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ada itu teman sekelas di sama dia cakap imut ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>berbicara soal orientasi studi dan pengenalan...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bajingan punya line</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kenali aku lebih dalam maka kamu akan menge i ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dalam acara back to kampus di fakultas ilmu bu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aku itu aku dan ku tau matamu sipit tapi dili...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>itu kalau benaran otoriter sebagaimana dilabel...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sepe i melihat punuk onta</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>asing yang bajingan surat pemberitahuan tahun...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>biar makin panas alias babi kaaaaau dan wkwk ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kenapa terguncang kamu mendengarnya pak makan...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>main ke pos ronda mengharapkan teman mengobrol...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mengapa bukan pt antam yang yang dipinjami ole...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweet Sentiment\n",
       "0    xf0 x9f x93 x8c himmler merupakan pimpinan di...  Positive\n",
       "1                                    iya anjir sudah   Negative\n",
       "2    ada itu teman sekelas di sama dia cakap imut ...  Positive\n",
       "3    berbicara soal orientasi studi dan pengenalan...  Positive\n",
       "4                                bajingan punya line   Negative\n",
       "5   kenali aku lebih dalam maka kamu akan menge i ...  Negative\n",
       "6   dalam acara back to kampus di fakultas ilmu bu...  Positive\n",
       "7    aku itu aku dan ku tau matamu sipit tapi dili...  Positive\n",
       "8   itu kalau benaran otoriter sebagaimana dilabel...  Positive\n",
       "9                          sepe i melihat punuk onta   Positive\n",
       "10   asing yang bajingan surat pemberitahuan tahun...  Negative\n",
       "11   biar makin panas alias babi kaaaaau dan wkwk ...  Negative\n",
       "12   kenapa terguncang kamu mendengarnya pak makan...  Positive\n",
       "13  main ke pos ronda mengharapkan teman mengobrol...  Negative\n",
       "14  mengapa bukan pt antam yang yang dipinjami ole...  Positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape: \", test.shape)\n",
    "train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13f5eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 10535\n",
      "TEST size: 2634\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN size:\", len(train))\n",
    "print(\"TEST size:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e48b89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 17765\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "SEQUENCE_LENGTH=300\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(train.Tweet)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) +1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c63f7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(tokenizer.texts_to_sequences(train.Tweet), maxlen=SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(test.Tweet), maxlen=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "740f329b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive', 'Negative']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train.Sentiment.unique().tolist()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19bb31af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (10535, 1)\n",
      "y_test (2634, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train.Sentiment.tolist())\n",
    "\n",
    "y_train = encoder.transform(train.Sentiment.tolist())\n",
    "y_test = encoder.transform(test.Sentiment.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "675001cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (10535, 300)\n",
      "y_train (10535, 1)\n",
      "\n",
      "x_test (2634, 300)\n",
      "y_test (2634, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edc5793b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48087eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [_Tweet.split() for _Tweet in train.Tweet] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b59fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "w2v_model = gensim.models.word2vec.Word2Vec(vector_size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)\n",
    "\n",
    "\n",
    "\n",
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdc232b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 2357\n"
     ]
    }
   ],
   "source": [
    "words = list(w2v_model.wv.key_to_index.keys())\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a69785d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4341469, 6216160)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea18d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM, Bidirectional\n",
    "from keras import utils\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b62646ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2357, 300)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  if word in w2v_model.wv:\n",
    "    embedding_matrix[i-1] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c615cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fcf6df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 300)          707100    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 300, 128)         186880    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 935,261\n",
      "Trainable params: 228,161\n",
      "Non-trainable params: 707,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(units=64, recurrent_dropout = 0.3, dropout = 0.3, \n",
    "                             return_sequences = True)))\n",
    "model.add(Bidirectional(LSTM(units=32, recurrent_dropout = 0.1, dropout = 0.1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d806d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a6963a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e7b3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "             EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacdf237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "149/149 [==============================] - 1445s 9s/step - loss: 0.5331 - acc: 0.7271 - val_loss: 0.4461 - val_acc: 0.7856 - lr: 0.0010\n",
      "Epoch 2/8\n",
      "149/149 [==============================] - 1441s 10s/step - loss: 0.4153 - acc: 0.8154 - val_loss: 0.3768 - val_acc: 0.8491 - lr: 0.0010\n",
      "Epoch 3/8\n",
      "149/149 [==============================] - 1489s 10s/step - loss: 0.3533 - acc: 0.8471 - val_loss: 0.3459 - val_acc: 0.8491 - lr: 0.0010\n",
      "Epoch 4/8\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=8,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b372e3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
